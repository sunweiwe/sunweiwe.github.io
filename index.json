[{"content":"Hi there 👋 # 🔭 I’m currently working on Java and Typescript. 🌱 I’m currently learning C++ \u0026amp; Java. 💬 Ask me about: Anything! 📫 How to reach me: sun_weiwe@163.com ","date":null,"permalink":"/","section":"","summary":"Hi there 👋 # 🔭 I’m currently working on Java and Typescript. 🌱 I’m currently learning C++ \u0026amp; Java. 💬 Ask me about: Anything! 📫 How to reach me: sun_weiwe@163.com ","title":""},{"content":"","date":null,"permalink":"/tags/database/","section":"Tags","summary":"","title":"Database"},{"content":"数据库 #CRUD #Insert # INSERT INTO user VALUES (10,\u0026#39;root\u0026#39;,\u0026#39;root\u0026#39;,\u0026#34;name@163.com\u0026#34;),(11,\u0026#39;user\u0026#39;,\u0026#39;user\u0026#39;,\u0026#34;name@163.com\u0026#34;); INSERT INTO user(username, password, email) VALUES (\u0026#39;admin\u0026#39;, \u0026#39;admin\u0026#39;, \u0026#39;xxxx@163.com\u0026#39;); Update #UPDATE user SET username=\u0026#39;root\u0026#39;,password=\u0026#39;root\u0026#39; WHERE username = \u0026#39;root\u0026#39;; Delte #DELETE FROM user WHERE username = \u0026#39;root\u0026#39;; // 清空表数据 TRUNCATE TABLE user; Select #SELECT name FROM user; SELECT id,name FROM user; SELECT * FROM user; SELECT DISINCT id FROM user; SELECT * FROM user LIMIT 5; SELECT * FROM user LIMIT 0,5; SELECT * FROM user LIMIT 2,3; 排序 # // desc 降序 SELECT * FROM user ORDER BY create_time ASC, age DESC 分组 #SELECT name, COUNT(address) AS addr_count FROM user GROUP BY name; SELECT name, COUNT(address) AS addr_count FROM user GROUP BY name ORDER BY name DESC; having # 对汇总的 group by 结果进行过滤 一般和 group by 连用 SELECT name, COUNT(*) AS count FROM user WHERE email IS NOT NULL GROUP BY name HAVING COUNT(*) \u0026gt;= 1; 子查询 #where #select column_name [, column_name ] from table1 [, table2 ] where column_name operator (select column_name [, column_name ] from table1 [, table2 ] [where]) from #select column_name [, column_name ] from (select column_name [, column_name ] from table1 [, table2 ] [where]) as temp_table_name where condition IN,BETWEEN #SELECT * FROM user WHERE id IN (\u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;); SELECT * FROM user WHERE age BETWEEN 3 AND 5; AND,OR,NOT # SELECT id, name, address FROM user WHERE name = \u0026#39;name\u0026#39; AND age \u0026gt;= 18; SELECT id, name, address FROM user WHERE name = \u0026#39;name\u0026#39; OR age \u0026gt;= 18; SELECT * FROM user WHERE age NOT BETWEEN 8 AND 18; 连接 # 连接表的本质就是将不同表的记录合并起来，形成一张新表。当然，这张新表只是临时的，它仅存在于本次查询期间。\n# join....on select c.cust_name, o.order_num from Customers c inner join Orders o on c.cust_id = o.cust_id order by c.cust_name; # 如果两张表的关联字段名相同，也可以使用USING子句：join....using() select c.cust_name, o.order_num from Customers c inner join Orders o using(cust_id) order by c.cust_name; 连接类型 说明 inner join （默认链接方式）只有两个标都存在满足条件的记录才会返回行。 left join/left outer join 返回左表的所有行，即使右表中没有满足条件的行也是如此。 right join/right outer join 返回右表中的所有行，即使左表没有满足条件的行也是如此。 full join/full outer join 返回其中一个表存在满足条件的记录。 self join 将一个表连接到自身，就像该表是两个表一样。为了区分两个表，在 SQL 语句中需要至少重命名一个表。 cross join 交叉连接，从两个或者多个连接表中返回记录集的笛卡尔积。 组合 # UNION 运算符将两个或更多查询的结果组合起来，并生成一个结果集，其中包含来自 UNION 中参与查询的提取行。\nUNION 基本规则：\n所有查询的列数和列顺序必须相同。 每个查询中涉及表的列的数据类型必须相同或兼容。 通常返回的列名取自第一个查询 SELECT column_name(s) FROM table1 UNION ALL SELECT column_name(s) FROM table2; 函数 #数据库定义 #数据库 #CREATE DATABASE test; DROP DATABASE test; USE test; 数据表 #CREATE TABLE user ( id int(10) unsigned NOT NULL COMMENT \u0026#39;Id\u0026#39;, username varchar(64) NOT NULL DEFAULT \u0026#39;default\u0026#39; COMMENT \u0026#39;用户名\u0026#39;, password varchar(64) NOT NULL DEFAULT \u0026#39;default\u0026#39; COMMENT \u0026#39;密码\u0026#39;, email varchar(64) NOT NULL DEFAULT \u0026#39;default\u0026#39; COMMENT \u0026#39;邮箱\u0026#39; ) COMMENT=\u0026#39;用户表\u0026#39;; CREATE TABLE vip_user AS SELECT * FROM user; DROP TABLE user; ALTER TABLE user ADD age int(3); ALTER TABLE user DROP COLUMN age; ALTER TABLE `user` MODIFY COLUMN age tinyint; ALTER TABLE user ADD PRIMARY KEY (id); ALTER TABLE user DROP PRIMARY KEY; 视图 #定义 # 视图是基于 SQL 语句的结果集的可视化的表。 视图是虚拟的表，本身不包含数据，也就不能对其进行索引操作。对视图的操作和对普通表的操作一样。 作用 # 简化复杂的 SQL 操作，比如复杂的联结； 只使用实际表的一部分数据； 通过只给用户访问视图的权限，保证数据的安全性； 更改数据格式和表示。 CREATE VIEW top_10_user_view AS SELECT id,name FROM user WHERE id \u0026lt; 10; DROP VIEW top_10_user_view; 索引 # 索引是一种用于快速查询和检索数据的数据结构，其本质可以看成是一种排序好的数据结构。\nCREATE INDEX user_index ON user (id); ALTER table user ADD INDEX user_index(id) CREATE UNIQUE INDEX user_index ON user (id); ALTER TABLE user DROP INDEX user_index; 约束 # NOT NULL UNIQUE PRIMARY KEY FOREIGN KEY CHECK DEFAULT CREATE TABLE Users ( Id INT(10) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT \u0026#39;自增Id\u0026#39;, Username VARCHAR(64) NOT NULL UNIQUE DEFAULT \u0026#39;default\u0026#39; COMMENT \u0026#39;用户名\u0026#39;, Password VARCHAR(64) NOT NULL DEFAULT \u0026#39;default\u0026#39; COMMENT \u0026#39;密码\u0026#39;, Email VARCHAR(64) NOT NULL DEFAULT \u0026#39;default\u0026#39; COMMENT \u0026#39;邮箱地址\u0026#39;, Enabled TINYINT(4) DEFAULT NULL COMMENT \u0026#39;是否有效\u0026#39;, PRIMARY KEY (Id) ) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8mb4 COMMENT=\u0026#39;用户表\u0026#39;; 事务处理 # START TRANSACTION - 指令用于标记事务的起始点。 SAVEPOINT - 指令用于创建保留点。 ROLLBACK TO - 指令用于回滚到指定的保留点；如果没有设置保留点，则回退到 START TRANSACTION 语句处。 COMMIT - 提交事务。 -- 开始事务 START TRANSACTION; -- 插入操作 A INSERT INTO `user` VALUES (1, \u0026#39;root1\u0026#39;, \u0026#39;root1\u0026#39;, \u0026#39;xxxx@163.com\u0026#39;); -- 创建保留点 updateA SAVEPOINT updateA; -- 插入操作 B INSERT INTO `user` VALUES (2, \u0026#39;root2\u0026#39;, \u0026#39;root2\u0026#39;, \u0026#39;xxxx@163.com\u0026#39;); -- 回滚到保留点 updateA ROLLBACK TO updateA; -- 提交事务，只有操作 A 生效 COMMIT; 存储过程 # 代码封装，保证了一定的安全性； 代码复用； 由于是预先编译，因此具有很高的性能。 DROP PROCEDURE IF EXISTS `proc_adder`; DELIMITER ;; CREATE DEFINER=`root`@`localhost` PROCEDURE `proc_adder`(IN a int, IN b int, OUT sum int) BEGIN DECLARE c int; if a is null then set a = 0; end if; if b is null then set b = 0; end if; set sum = a + b; END ;; DELIMITER ; ","date":"22.11.2023","permalink":"/posts/database/database/syntax/","section":"Posts","summary":"数据库的基本语法使用","title":"database syntax"},{"content":"","date":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts"},{"content":"","date":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"","date":null,"permalink":"/tags/java/","section":"Tags","summary":"","title":"Java"},{"content":"并发 #线程 #线程状态 # New Runnable Blocked Waiting Timed waiting Terminated synchronized # 可重入 public class Bank{ private Lock lock = new ReentrantLock(); private Condition sufficientFunds; public Bank(){ sufficientFunds = lock.newCondition(); } public void transfer(int from, int amount){ lock.lock();// a ReentrantLock object try{ // critical section while(accounts[form] \u0026lt; amount){ // 挂起线程，释放锁 sufficientFunds.await(); } sufficientFunds.signalAll(); }finally{ lock.unlock(); } } // OR public synchronized void syncTransfer(int from,int amount) throw InterruptedException { while(accounts[from] \u0026lt; amount) wait(); accounts[from] -= amount; accounts[to] += amount; notifyAll(); } } volatile 和 final # 保证数据的可见性，但不保证数据的原子性。 防止JVM的指令重排。插入特定的 内存屏障的方式禁止指令重排序。 public native void loadFence(); public native void storeFence(); public native void fullFence(); 原子性 # AtomicIntegerFieldupdater 原子更新整型字段的更新器 AtmoicLongFieldUpdater 原子更新长整型字段的更新器 AtmoicReferenceFieldUpdater 原子更新引用类型里的字段 public static AtmoicLong nextNumber = new AtomicLong(); long id = nextNumber.incrementAndGet(); 锁 #private ReentrantReadWriteLock rw = new ReentrantReadWriterLock(); private Lock readLock = rw.readLock(); private Lock writeLock = rw.writeLock(); public doube getTotalBalance() { readLock.lock(); try{ }finally{ readLock.unlock(); } } public void transfer(){ writeLock.lock(); try{ }finally{ writeLock.unlock(); } } 线程安全的集合 # ConcurrentHashMap ConcurrentSkipListMap ConcurrentSkipListSet ConcurrentLinkedQueue 执行器 # newCachedThreadPool newFiexdThreadPool newSingleThreadExcutor newScheduledThreadPool newSingleThreadScheduledExcutor ","date":"16.11.2023","permalink":"/posts/java/java/thread/","section":"Posts","summary":"Java thread 相关知识点","title":"thread"},{"content":"字符串 # 缓存功能 计算器 统计多单位的数量 共享用户session SET key value [EX seconds|PX milliseconds|EXAT timestamp|PXAT milliseconds-timestamp|KEEPTTL] [NX|XX] [GET] List(列表) # list类型是用来存储多个有序的字符串的，列表当中的每一个字符看做一个元素 一个列表当中可以存储有一个或者多个元素，redis的list支持存储2^32次方-1个元素。 redis可以从列表的两端进行插入（pubsh）和弹出（pop）元素，支持读取指定范围的元素集，或者读取指定下标的元素等操作。redis列表是一种比较灵活的链表数据结构，它可以充当队列或者栈的角色。 redis列表是链表型的数据结构，所以它的元素是有序的，而且列表内的元素是可以重复的。意味着它可以根据链表的下标获取指定的元素和某个范围内的元素集。 使用场景 # 消息队列：reids的链表结构，可以轻松实现阻塞队列，可以使用左进右出的命令组成来完成队列的设计。比如：数据的生产者可以通过Lpush命令从左边插入数据，多个数据消费者，可以使用BRpop命令阻塞的“抢”列表尾部的数据。\n文章列表或者数据分页展示的应用。比如，我们常用的博客网站的文章列表，当用户量越来越多时，而且每一个用户都有自己的文章列表，而且当文章多时，都需要分页展示，这时可以考虑使用redis的列表，列表不但有序同时还支持按照范围内获取元素，可以完美解决分页查询功能。大大提高查询效率。\nSet(集合) # redis集合（set）类型和list列表类型类似，都可以用来存储多个字符串元素的集合。 但是和list不同的是set集合当中不允许重复的元素。而且set集合当中元素是没有顺序的，不存在元素下标。 redis的set类型是使用哈希表构造的，因此复杂度是O(1)，它支持集合内的增删改查， 并且支持多个集合间的交集、并集、差集操作。可以利用这些集合操作，解决程序开发过程当中很多数据集合间的问题。 使用场景 # 标签：比如我们博客网站常常使用到的兴趣标签，把一个个有着相同爱好，关注类似内容的用户利用一个标签把他们进行归并。\n共同好友功能。\n统计网站的独立IP\nsorted set（有序集合） # redis有序集合也是集合类型的一部分，所以它保留了集合中元素不能重复的特性，但是不同的是，有序集合给每个元素多设置了一个分数。\n应用场景 # 排行榜：有序集合经典使用场景。例如视频网站需要对用户上传的视频做排行榜，榜单维护可能是多方面：按照时间、按照播放量、按照获得的赞数等。 用Sorted Sets来做带权重的队列，比如普通消息的score为1，重要消息的score为2，然后工作线程可以选择按score的倒序来获取工作任务。让重要的任务优先执行。 5 hash（哈希） # 存储用户相关信息。优化用户信息的获取，不需要重复从数据库当中读取，提高系统性能。 Bitmaps（位存储） #持久化 # 快照（RDB文件）RDB持久化方式会在一个特定的间隔保存那个时间点的数据快照。\n追加式文件（AOF文件）AOF持久化方式则会记录每一个服务器收到的写操作。在服务启动时，这些记录的操作会逐条执行从而重建出原来的数据。写操作命令记录的格式跟Redis协议一致，以追加的方式进行保存。\n","date":"15.11.2023","permalink":"/posts/redis/redis/basic/","section":"Posts","summary":"redis基本数据类型和用法","title":"basic"},{"content":"","date":null,"permalink":"/tags/redis/","section":"Tags","summary":"","title":"Redis"},{"content":"从迭代到流的操作 # var contents = new String(Files.readAllBytes( Paths.get(\u0026#34;alice.txt\u0026#34;)),StandardCharsets.UTF_8); List\u0026lt;String\u0026gt; words = List.of(contents.split(\u0026#34;\\\\PL+\u0026#34;)); int count = 0; for (String w : words){ if (w.length()\u0026gt;12) count++; } long count = words.parallelStream().filter(w -\u0026gt; w.length() \u0026gt;12 ).count(); ","date":"15.11.2023","permalink":"/posts/java/java/stream/","section":"Posts","summary":"Java流的概念和用法","title":"stream"},{"content":"","date":null,"permalink":"/tags/stream/","section":"Tags","summary":"","title":"Stream"},{"content":"面向对象 # 封装 继承 多态 类 # 构造器和类同名 每个类可以有一个以上构造器 构造器可以有0,1或多个参数 构造器没有返回值 构造器总伴随着new操作符一起调用 继承 # 使用 extends\n覆盖方法 # override\n阻止继承: fianl类和方法 #泛型数组列表(容器) #声明 #ArrayList\u0026lt;String\u0026gt; s = new ArrayList\u0026lt;String\u0026gt;(); var s = new ArrayList\u0026lt;String\u0026gt;(); ArrayList\u0026lt;String\u0026gt; s = new ArrayList\u0026lt;\u0026gt;(); 对象包装器与自动装箱 # Integer Long Float Double Short Byte Character Boolean 接口 #概念 # 接口不是类, 而是对希望符合这个接口的类的一组需求\n类实现接口 # 将类声明为实现给定的接口 对接口中的所有方法提供定义 class Employee implements Comparable\u0026lt;Employee\u0026gt; { public int compareTo(Object otherObject){ Employee other = (Emplyoee) otherObject; return Double.compare(salary,other.salary); } } ","date":"15.11.2023","permalink":"/posts/java/java/class/","section":"Posts","summary":"类的使用","title":"class"},{"content":"数据类型 # 八种基本类型，其中四种整型，两种浮点类型，1种字符串类型和一种真值类型\n整型 # 类型 存储需求 取值范围 int 4字节 -2147483648 ~ 2147483647 short 2字节 -32768 ~ 32767 long 8字节 -9223372036854775808 ~ 9223372036854775807 byte 1字节 -128 ~ 127 浮点型 # 类型 存储需求 取值范围 float 4字节 大约 +- 3.40282347E+38F (有效位数为6~7位) double 8字节 大约 +- 1.79769313486231570E+308 (有效位数为15位) 常量 # 使用 final 指示常量，使用 static final 声明类常量。\n枚举类型 #enum Size { SMALL, MEDIUM, LARGE, EXTRA_LARGE }; 位运算符 # \u0026amp; and | or ^ xor ~ not \u0026laquo; 右移 左移\n字符串 # 使用 equals 方法检测是否相等。 == 只能确定是否存放在同一个位置。\nStringBuilder builder = new StringBuilder(); builder.append(ch); String completedString = builder.toString(); 输入与输出 #读取输入 #Scanner in = new Scanner(System.in); System.out.print(\u0026#34;What\u0026#39;s up?\u0026#34;); String name = in.nextLine(); String firstName = in.next(); // 读取密码 Console cons = System.consloe(); String username = cons.readLine(\u0026#34;User name: \u0026#34;); char[] password = cons.readPassword(\u0026#34;Password: \u0026#34;); 格式化输出 # System.out.print, System.out.printf\n转换符 类型 实例 d 十进制整数 159 x 十六进制整数 9f o 八进制整数 237 f 定点浮点数 15.9 e 指点浮点数 15.9e+01 g 通用浮点数（e和f中较短的一个） 15.9e+01 a 十六进制浮点数 0x1.fccdp3 s 字符串 Hello c 字符 H b 布尔 true h 散列码 42628b2 tx或Tx 日期时间(T强制大写) 已经过时，使用 java.time n 与平台有关的行分隔符 - 文件输入于输出 # // 读文件 Scanner in = new Scanner(Path.of(\u0026#34;file.txt\u0026#34;),StandardCharsets.UTF_8); // 写文件 PrintWriter out = new PrintWriter(\u0026#34;file.txt\u0026#34;,StandardCharsets.UTF_8); 大数 # BigInter \u0026amp; BigDecimal\nBiginteger value = BigInteger.valueOf(100); BigInteger r = new BigInteger(\u0026#34;222323421312432423423423432423432423423434\u0026#34;); constants # BigInteger.ZERO BigInteger.ONE BigInteger.TEN BigInteger.TWO 大数的算术运算需要使用 add 和 multiply 方法\nlotteryOdds = lotteryOdds * (n - i + 1)/i; lotteryOdds = lotteryOdds.multiply(BigInterger.valueOf(n - i + 1)).divide(BigInteger.valueOf(i)); 数组 #声明数组 #int[] numbers; int a = new int[100]; int[] s = { 2,3,4}; for(int v: s){ System.out.println(v); } 数组拷贝 #// 指向同一个地址 int[] before = {1,2}; int[] after = before; // 拷贝到新的数组中 int[] differ = Arrays.copyOf(before,before.length); 数组排序 # sort 方法使用了优化的快速排序算法\nint[] a = new int[1000]; Arrays.sort(a); ","date":"15.11.2023","permalink":"/posts/java/java/syntax/","section":"Posts","summary":"Java的基本数据类型","title":"syntax"},{"content":"","date":null,"permalink":"/tags/syntax/","section":"Tags","summary":"","title":"Syntax·"},{"content":"使用场景 # 比如下面是通过 JDK 实现动态代理的示例代码，其中就使用了反射类 Method 来调用指定的方法。\n运行时分析类的能力 在运行时检查对象 实现泛型数组操作代码 利用method对象 public class DebugInvocationHandler implements InvocationHandler { /** * 代理类中的真实对象 */ private final Object target; public DebugInvocationHandler(Object target) { this.target = target; } public Object invoke(Object proxy, Method method, Object[] args) throws InvocationTargetException, IllegalAccessException { System.out.println(\u0026#34;before method \u0026#34; + method.getName()); Object result = method.invoke(target, args); System.out.println(\u0026#34;after method \u0026#34; + method.getName()); return result; } } 基本操作 #package cn.app public class TargetObject { private String value; public TargetObject() { value = \u0026#34;App\u0026#34; } public void publicMethod(String s) { System.out.println(\u0026#34;This is \u0026#34;+ s ); } private void privateMethod(){ System.out.println(\u0026#34;value is \u0026#34;+ value); } } package cn.app; import java.lang.reflect.Field; import java.lang.reflect.InvocationTargetException; import java.lang.reflect.Method; public class Main { public static void main(String[] args) throws ClassNotFoundException, NoSuchMethodException, IllegalAccessException, InstantiationException, InvocationTargetException, NoSuchFieldException { /** * 获取 TartgetObject 类的Class 对象并且创建 TartgetObject 类实例 */ Class\u0026lt;?\u0026gt; tartgetClass = class.forName(\u0026#34;cn.app.TartgetObject\u0026#34;); TargetObject tartgetObject = (TargetObject) targetClass.newInstance(); Method[] methods = targetClass.getDeclaredMethods(); for (Method method: methods){ System.out.println(method.getName()); } Method publicMethod = targetClass.getDeclaredMethod(\u0026#34;publicMethod\u0026#34;,String.class); publicMethod.invoke(tartgetObject,\u0026#34;sunweiwe\u0026#34;); Field field = tartgetClass.getDeclaredField(\u0026#34;value\u0026#34;); field.setAccessible(true); field.set(tartgetObject,\u0026#34;sunweiwe\u0026#34;); Method privateMethod = tartgetClass.getDeclaredMethod(\u0026#34;privateMethod\u0026#34;); privateMethod.setAccessible(true); privateMethod.invoke(tartgetObject); } } ","date":"15.11.2023","permalink":"/posts/java/java/reflect/","section":"Posts","summary":"Java 反射基本使用","title":"reflect"},{"content":"","date":null,"permalink":"/tags/reflect/","section":"Tags","summary":"","title":"Reflect"},{"content":"注解 #SpringBootApplication #@SpringBootApplication public class SpringSecurityJwtGuideApplication { public static void main(java.lang.String[] args) { SpringApplication.run(SpringSecurityJwtGuideApplication.class, args); } } // 相当于 @ComponentScan @Configuration @EnableAutoConfiguration package org.springframework.boot.autoconfigure; @Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @SpringBootConfiguration @EnableAutoConfiguration @ComponentScan(excludeFilters = { @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) }) public @interface SpringBootApplication { ...... } package org.springframework.boot; @Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Documented @Configuration public @interface SpringBootConfiguration { } @EnableAutoConfiguration：启用 SpringBoot 的自动配置机制 @ComponentScan：扫描被@Component (@Repository,@Service,@Controller)注解的 bean，注解默认会扫描该类所在的包下所有的类。 @Configuration：允许在 Spring 上下文中注册额外的 bean 或导入其他配置类 Autowired #自动导入对象到类中，被注入进的类同样要被 Spring 容器管理比如：Service 类注入到 Controller 类中。\n@Service public class UserService { ...... } @RestController @RequestMapping(\u0026#34;/users\u0026#34;) public class UserController { @Autowired private UserService userService; ...... } Component Service Controller Repository #我们一般使用 @Autowired 注解让 Spring 容器帮我们自动装配 bean。要想把类标识成可用于 @Autowired 注解自动装配的 bean 的类,可以采用以下注解实现：\n@Component：通用的注解，可标注任意类为 Spring 组件。如果一个 Bean 不知道属于哪个层，可以使用@Component 注解标注。 @Repository : 对应持久层即 Dao 层，主要用于数据库相关操作。 @Service : 对应服务层，主要涉及一些复杂的逻辑，需要用到 Dao 层。 @Controller : 对应 Spring MVC 控制层，主要用于接受用户请求并调用 Service 层返回数据给前端页面。 RestController #@RestController注解是@Controller和@ResponseBody的合集,表示这是个控制器 bean,并且是将函数的返回值直接填入 HTTP 响应体中,是 REST 风格的控制器。\nScope #声明 Spring Bean 的作用域，使用方法:\n@Bean @Scope(\u0026#34;singleton\u0026#34;) public Person personSingleton() { return new Person(); } singleton : 唯一 bean 实例，Spring 中的 bean 默认都是单例的。 prototype : 每次请求都会创建一个新的 bean 实例。 request : 每一次 HTTP 请求都会产生一个新的 bean，该 bean 仅在当前 HTTP request 内有效。 session : 每一个 HTTP Session 会产生一个新的 bean，该 bean 仅在当前 HTTP session 内有效。 Configuration #一般用来声明配置类，可以使用 @Component注解替代，不过使用@Configuration注解声明配置类更加语义化。\n@Configuration public class AppConfig { @Bean public TransferService transferService() { return new TransferServiceImpl(); } } PathVariable #@PathVariable用于获取路径参数，@RequestParam用于获取查询参数。\n@GetMapping(\u0026#34;/user/{id}/teachers\u0026#34;) public List\u0026lt;Teacher\u0026gt; getKlassRelatedTeachers( @PathVariable(\u0026#34;id\u0026#34;) Long id, @RequestParam(value = \u0026#34;type\u0026#34;, required = false) String type ) { ... } // 请求的 url 是：/user/123456/teachers?type=web // 服务获取到的数据就是：id=123456,type=web Value #使用 @Value(\u0026quot;${property}\u0026quot;) 读取比较简单的配置信息：\n@Value(\u0026#34;${wuhan2020}\u0026#34;) String wuhan2020; ConfigurationProperties #通过@ConfigurationProperties读取配置信息并与 bean 绑定。\n@Component @ConfigurationProperties(prefix = \u0026#34;library\u0026#34;) class LibraryProperties { @NotEmpty private String location; private List\u0026lt;Book\u0026gt; books; @Setter @Getter @ToString static class Book { String name; String description; } // 省略getter/setter } Transactional #在要开启事务的方法上使用@Transactional注解即可!\n@Transactional(rollbackFor = Exception.class) public void save() { ...... } 作用于类：当把@Transactional 注解放在类上时，表示所有该类的 public 方法都配置相同的事务属性信息。 作用于方法：当类配置了@Transactional，方法也配置了@Transactional，方法的事务会覆盖类的事务配置信息。 事务的特性（ACID） # 原子性（Atomicity）：事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用； 一致性（Consistency）：执行事务前后，数据保持一致，例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的； 隔离性（Isolation）：并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的； 持久性（Durability）：一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。 ","date":"14.11.2023","permalink":"/posts/java/java/basic/","section":"Posts","summary":"Spring boot注解基本用法","title":"basic"},{"content":"集合(容器) #接口和实现分离 # // 队列接口 public interface Queue\u0026lt;E\u0026gt; { void add(E element); E remove(); int size(); } // public class CircularArrayQueue\u0026lt;E\u0026gt; implements Queue\u0026lt;E\u0026gt; { private int head; private int tail; CircularArrayQueue(int capacity) {} public void add(E element){} public E remove() {} public int size() {} private E[] elements; } public class LinkedListQueue\u0026lt;E\u0026gt; implements Queue\u0026lt;E\u0026gt; { private Link head; private Link tail; LinkedListQueue() {} public void add(E element) {} public E remove() {} public int size() {} } 迭代器 # 使用 next 方法逐个访问集合中的每个元素。但是，如何到达集合的末尾，next 方法将抛出一个 NoSuchElementException\nCollection\u0026lt;String\u0026gt; c =...; Iterator\u0026lt;String\u0026gt; iter = c.iterator(); while(iter.hasNext()) { String element = iter.next(); // logic } // or for(String element : c){ // logic } // for 集合(容器)。分为两类: Collection 和 Map\npublic interface Collection\u0026lt;E\u0026gt; { boolean add(E element); Iterator\u0026lt;E\u0026gt; iterator(); } public interface Iterator\u0026lt;E\u0026gt; { E next(); boolean hasNext(); void remove(); default void forEachRemaining(Consumer\u0026lt;? super E\u0026gt; action); } public interface Iterable\u0026lt;E\u0026gt; { Iterator\u0026lt;E\u0026gt; iterator(); } Collection # Collection 接口扩展了 Iterable 接口\nSet\nadd 方法不允许增加重复的元素。equals 方法认为两个集合包含相同的元素就相等，不要求顺序相同。\nHashSet: 无续，唯一。基于HashMap实现\nSet\u0026lt;String\u0026gt; words = new HashSet\u0026lt;\u0026gt;(Arrays.asList(\u0026#34;A\u0026#34;, \u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;, \u0026#34;C\u0026#34;, \u0026#34;B\u0026#34;, \u0026#34;My\u0026#34;, \u0026#34;MY\u0026#34;, \u0026#34;My\u0026#34;)); words.add(\u0026#34;D\u0026#34;); for (String w : words) { System.out.println(w); } Iterator\u0026lt;String\u0026gt; iterator = words.iterator(); while (iterator.hasNext()) { System.out.println(iterator.next()); } TreeSet: 有序，唯一。红黑树（自平衡的排序二叉树）\nSortedSet\u0026lt;String\u0026gt; sorter = new TreeSet\u0026lt;\u0026gt;(); sorter.add(\u0026#34;Bob\u0026#34;); sorter.add(\u0026#34;Amy\u0026#34;); sorter.add(\u0026#34;Carl\u0026#34;); for (String s : sorter) System.out.println(s); LinkedHashSet: LinkedHashSet 是 HashSet 的子类，并且其内部是通过 LinkedHashMap 来实现的。\nList\n分为两种实现，数组和链表。数组支持随机访问。\nif (c instanceof RandomAccess){ // 使用随机访问算法 }else{ // 线性访问 } ArrayList: Object[] 数组\n非同步，线程不安全 继承自 AbstractList，实现了 List RandomAccess Cloneable java.io.Serializable 接口。 public class ArrayList\u0026lt;E\u0026gt; extends AbstractList\u0026lt;E\u0026gt; implements List\u0026lt;E\u0026gt;, RandomAceess, Cloneable, java.io.Serializeable { private static final long serivalVersionUID = 8683452581122892189L; /** * 默认初始化大小 */ private static final int DEFAULT_CAPACITY = 10; /** * 空数组 */ private static final Object[] EMPTY_ELEMENTDATA = {}; //用于默认大小空实例的共享空数组实例。 //我们把它从EMPTY_ELEMENTDATA数组中区分出来，以知道在添加第一个元素时容量需要增加多少。 private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {}; } List\u0026lt;String\u0026gt; chars = new ArrayList\u0026lt;\u0026gt;(); // or List\u0026lt;String\u0026gt; names = new ArrayList\u0026lt;\u0026gt;(Arrays.asList(\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;, \u0026#34;C\u0026#34;)); chars.add(\u0026#34;A\u0026#34;); chars.add(\u0026#34;B\u0026#34;); chars.add(\u0026#34;C\u0026#34;); name.removeIf(c-\u0026gt;c.equals(\u0026#34;B\u0026#34;)); System.out.println(names.size()); // c 是 cllection names.addAll(c); // true names.contains(\u0026#34;A\u0026#34;); LinkedList: 双向链表\n双端队列的链表实现。 不支持随机访问。 List\u0026lt;String\u0026gt; staff = new LinkedList\u0026lt;\u0026gt;(); staff.add(\u0026#34;Amy\u0026#34;); staff.add(\u0026#34;Bob\u0026#34;); staff.add(\u0026#34;Carl\u0026#34;); // or List\u0026lt;String\u0026gt; staff = new LinkedList\u0026lt;\u0026gt;(Arrays.asList(\u0026#34;Amy\u0026#34;, \u0026#34;Bob\u0026#34;, \u0026#34;Carl\u0026#34;)); ListIterator\u0026lt;String\u0026gt; iter = staff.listIterator(); iter.next(); iter.add(\u0026#34;Juliet\u0026#34;); while (iter.hasNext()) { System.out.println(iter.next()); } Queue\nPriorityQueue: Object[] 数组实现的小顶堆\n非线程安全，且不支持存储 NULL 和 non-comparable 对象。 可以接收一个 Comparator 作为构造参数自定义元素优先级的先后。 PriorityQueue\u0026lt;LocalDate\u0026gt; pq = new PriorityQueue\u0026lt;\u0026gt;(); DelayQueue: PriorityQueue\nArrayDeque: 可扩容动态双向数组。\n线程不安全。 不支持 null 值。 双端队列的数组实现。 ArrayDeque\u0026lt;Integer\u0026gt; deque = new ArrayDeque\u0026lt;\u0026gt;(Arrays.asList(2, 4, 6)); // 返回并删除队首元素 // 为空抛出 NoSuchElementException deque.remove(); // 为空返回null deque.poll(); // 返回但不删除队首元素 // 为空抛出 NoSuchElementException deque.element(); // 为空返回null deque.peek(); Map # HashMap: JDK1.8 之前 HashMap 由数组+链表组成的，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）。JDK1.8 以后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间。\n非线程安全， ConcurrentHashMap 使用键（Key）计算 hashcode Map\u0026lt;String,String\u0026gt; user = new HashMap\u0026lt;\u0026gt;(); user.put(\u0026#34;\u0026lt;key\u0026gt;\u0026#34;,\u0026#34;value\u0026#34;); e = user.get(\u0026#34;\u0026lt;key\u0026gt;\u0026#34;); user.getOrDefault(\u0026#34;1\u0026#34;, \u0026#34;\u0026#34;); for (Map.Entry\u0026lt;String, String\u0026gt; entry : user.entrySet()) { String k = entry.getKey(); String v = entry.getValue(); System.out.println(\u0026#34;key: \u0026#34; + k + \u0026#34; value: \u0026#34; + v); } // or user.forEach((k, v) -\u0026gt; { System.out.println(\u0026#34;key: \u0026#34; + k + \u0026#34; value: \u0026#34; + v); }) LinkedHashMap: LinkedHashMap 继承自 HashMap，所以它的底层仍然是基于拉链式散列结构即由数组和链表或红黑树组成。另外，LinkedHashMap 在上面结构的基础上，增加了一条双向链表，使得上面的结构可以保持键值对的插入顺序。同时通过对链表进行相应的操作，实现了访问顺序相关逻辑。\n//! TODO\nHashtable: 数组+链表组成的，数组是 Hashtable 的主体，链表则是主要为了解决哈希冲突而存在的。\nTreeMap: 红黑树（自平衡的排序二叉树）。\n","date":"14.11.2023","permalink":"/posts/java/java/collection/","section":"Posts","summary":"Java 集合","title":"basic"},{"content":"","date":null,"permalink":"/tags/collection/","section":"Tags","summary":"","title":"Collection"},{"content":"什么是 SpringBoot 自动装配？ # SpringBoot 定义了一套接口规范，这套规范规定：SpringBoot 在启动时会扫描外部引用 jar 包中的 META-INF/spring.factories 文件，将文件中配置的类型信息加载到 Spring 容器（此处涉及到 JVM 类加载机制与 Spring 的容器知识），并执行类中定义的各种操作。对于外部 jar 来说，只需要按照 SpringBoot 定义的标准，就能将自己的功能装置进 SpringBoot。\n自动装配可以简单理解为：通过注解或者一些简单的配置就能在 Spring Boot 的帮助下实现某块功能。\nSpringBoot 是如何实现自动装配的？ #@Target({ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited \u0026lt;1.\u0026gt;@SpringBootConfiguration \u0026lt;2.\u0026gt;@ComponentScan \u0026lt;3.\u0026gt;@EnableAutoConfiguration public @interface SpringBootApplication { } @Target({ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @Documented @Configuration //实际上它也是一个配置类 public @interface SpringBootConfiguration { } 大概可以把 @SpringBootApplication看作是 @Configuration、@EnableAutoConfiguration、@ComponentScan 注解的集合。根据 SpringBoot 官网，这三个注解的作用分别是：\n@EnableAutoConfiguration：启用 SpringBoot 的自动配置机制 @Configuration：允许在上下文中注册额外的 bean 或导入其他配置类 @ComponentScan：扫描被@Component (@Service,@Controller)注解的 bean，注解默认会扫描启动类所在的包下所有的类 ，可以自定义不扫描某些 bean。如下图所示，容器中将排除TypeExcludeFilter和AutoConfigurationExcludeFilter @EnableAutoConfiguration:实现自动装配的核心注解 # EnableAutoConfiguration 只是一个简单地注解，自动装配核心功能的实现实际是通过 AutoConfigurationImportSelector类。\n@Target({ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @AutoConfigurationPackage //作用：将main包下的所有组件注册到容器中 @Import({AutoConfigurationImportSelector.class}) //加载自动装配类 xxxAutoconfiguration public @interface EnableAutoConfiguration { String ENABLED_OVERRIDE_PROPERTY = \u0026#34;spring.boot.enableautoconfiguration\u0026#34;; Class\u0026lt;?\u0026gt;[] exclude() default {}; String[] excludeName() default {}; } AutoConfigurationImportSelector:加载自动装配类 #public class AutoConfigurationImportSelector implements DeferredImportSelector, BeanClassLoaderAware, ResourceLoaderAware, BeanFactoryAware, EnvironmentAware, Ordered { } public interface DeferredImportSelector extends ImportSelector { } public interface ImportSelector { String[] selectImports(AnnotationMetadata var1); } 可以看出，AutoConfigurationImportSelector 类实现了 ImportSelector接口，也就实现了这个接口中的 selectImports方法，该方法主要用于获取所有符合条件的类的全限定类名，这些类需要被加载到 IoC 容器中。\nprivate static final String[] NO_IMPORTS = new String[0]; public String[] selectImports(AnnotationMetadata annotationMetadata) { // \u0026lt;1\u0026gt;.判断自动装配开关是否打开 if (!this.isEnabled(annotationMetadata)) { return NO_IMPORTS; } else { //\u0026lt;2\u0026gt;.获取所有需要装配的bean AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader.loadMetadata(this.beanClassLoader); AutoConfigurationImportSelector.AutoConfigurationEntry autoConfigurationEntry = this.getAutoConfigurationEntry(autoConfigurationMetadata, annotationMetadata); return StringUtils.toStringArray(autoConfigurationEntry.getConfigurations()); } } private static final AutoConfigurationEntry EMPTY_ENTRY = new AutoConfigurationEntry(); AutoConfigurationEntry getAutoConfigurationEntry(AutoConfigurationMetadata autoConfigurationMetadata, AnnotationMetadata annotationMetadata) { //\u0026lt;1\u0026gt;. if (!this.isEnabled(annotationMetadata)) { return EMPTY_ENTRY; } else { //\u0026lt;2\u0026gt;. AnnotationAttributes attributes = this.getAttributes(annotationMetadata); //\u0026lt;3\u0026gt;. List\u0026lt;String\u0026gt; configurations = this.getCandidateConfigurations(annotationMetadata, attributes); //\u0026lt;4\u0026gt;. configurations = this.removeDuplicates(configurations); Set\u0026lt;String\u0026gt; exclusions = this.getExclusions(annotationMetadata, attributes); this.checkExcludedClasses(configurations, exclusions); configurations.removeAll(exclusions); configurations = this.filter(configurations, autoConfigurationMetadata); this.fireAutoConfigurationImportEvents(configurations, exclusions); return new AutoConfigurationImportSelector.AutoConfigurationEntry(configurations, exclusions); } } 判断自动装配开关是否打开。默认spring.boot.enableautoconfiguration=true，可在 application.properties 或 application.yml 中设置 用于获取EnableAutoConfiguration注解中的 exclude 和 excludeName。 获取需要自动装配的所有配置类，读取META-INF/spring.factories 如何实现一个 Starter # 创建工程 (-spring-boot-starter) 引入 Spring Boot 相关依赖 （ spring boot stater 基础库） 创建(PoolAutoConfiguration) @Configuration public class \u0026lt;Name\u0026gt;AutoConfiguration { @Bean @ConditiononClass(ThreadPoolExecutor.class) public ThreadPoolExecutor Classname(){ return new ThreadPoolExecutor() } } 在 \u0026lt;name\u0026gt;-spring-boot-starter工程的 resources 包下创建META-INF/spring.factories文件 ","date":"14.11.2023","permalink":"/posts/java/java/autoconfig/","section":"Posts","summary":"Spring boot 自动转配的概念和原理","title":"SpringBoot 自动装配原理"},{"content":"","date":null,"permalink":"/tags/cgroup/","section":"Tags","summary":"","title":"cgroup"},{"content":"cgroup #mount #目前支持的挂载方式为：\nnsdelegate favordynmods memory_localevents 只能挂载时设置或者通过从 init 命名空间重新挂载来修改，这是系统范围的选项。只用当前 cgroup 的数据填充 memory.events，如果没有这个选项，默认会计数所有子树； memory_recursiveprot 递归地将 memory.min 和 memory.low 保护应用于整个子树，无需显式向下传播到叶节点的 cgroup 中，子树内叶子节点可以自由竞争 组织进程和线程 #进程 #每个 cgroup 有一个可读写的的文件 cgroup.procs\n线程 #","date":"14.03.2023","permalink":"/posts/linux/linux/cgroup/","section":"Posts","summary":"for linux cgroup","title":"cgroup"},{"content":"","date":null,"permalink":"/tags/docker/","section":"Tags","summary":"","title":"docker"},{"content":"","date":null,"permalink":"/tags/linux/","section":"Tags","summary":"","title":"linux"},{"content":"","date":null,"permalink":"/tags/ubuntu/","section":"Tags","summary":"","title":"ubuntu"},{"content":"拉取镜像 #docker pull ubuntu 创建容器 #docker run -i -t --name ubuntu ubuntu bash Ubuntu 基本配置 #apt-get update apt-get install vim 更新软件源 #/etc/apt/sources.list\ndeb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse apt-get update apt-get install git 配置 SSH #apt-get install openssh-server 配置 sshd #/etc/ssh/sshd_config\nPermitRootLogin yes # 可以登录 root 用户 PubkeyAuthentication yes # 可以使用 ssh 公钥许可 AuthorizedKeysFile\t.ssh/authorized_keys # 公钥信息保存到文件 .ssh/authorized_keys 中 重启 sshd #/etc/init.d/ssh restart 主机 SSH 公钥 # 在 HOME 目录下创建 .ssh 目录：mkdir ~/.ssh 新建文件 ~/.ssh/authorized_keys ：touch ~/.ssh/authorized_keys 新开一个 macOS 下的终端窗口，执行命令 cat ~/.ssh/id_rsa.pub，复制打印的一行公钥信息 回到 ubuntu 容器中，将第 3 步复制的公钥粘贴到 ~/.ssh/authorized_keys 中保存。 提交修改到镜像 #docker commit -m \u0026lt;Comment\u0026gt; -a \u0026lt;Author\u0026gt; \u0026lt;containerId\u0026gt; \u0026lt;ImageName\u0026gt; ","date":"14.03.2023","permalink":"/posts/linux/linux/ubuntu/","section":"Posts","summary":"ubuntu in docker","title":"Ubuntu in docker"},{"content":"","date":null,"permalink":"/tags/kubernetes/","section":"Tags","summary":"","title":"kubernetes"},{"content":"调度器配置 #你可以通过编写配置文件，并将其路径传给 kube-scheduler 的命令行参数，定制 kube-scheduler 的行为。\n调度模板（Profile）允许你配置 kube-scheduler 中的不同调度阶段。每个阶段都暴露于某个扩展点中。插件通过实现一个或多个扩展点来提供调度行为。\n你可以通过运行 kube-scheduler \u0026ndash;config 来设置调度模板， 使用 KubeSchedulerConfiguration（v1beta3 或 v1）结构体。\napiVersion: kubescheduler.config.k8s.io/v1 kind: KubeSchedulerConfiguration clientConnection: kubeconfig: /etc/srv/kubernetes/kube-scheduler/kubeconfig 说明： 配置文件 #调度行为发生在一系列阶段中，这些阶段是通过以下扩展点公开的：\n扩展点 # queueSort：这些插件对调度队列中的悬决的 Pod 排序。 一次只能启用一个队列排序插件。 preFilter：这些插件用于在过滤之前预处理或检查 Pod 或集群的信息。 它们可以将 Pod 标记为不可调度。 filter：这些插件相当于调度策略中的断言（Predicates），用于过滤不能运行 Pod 的节点。 过滤器的调用顺序是可配置的。 如果没有一个节点通过所有过滤器的筛选，Pod 将会被标记为不可调度。 postFilter：当无法为 Pod 找到可用节点时，按照这些插件的配置顺序调用他们。 如果任何 postFilter 插件将 Pod 标记为可调度，则不会调用其余插件。 preScore：这是一个信息扩展点，可用于预打分工作。 score：这些插件给通过筛选阶段的节点打分。调度器会选择得分最高的节点。 reserve：这是一个信息扩展点，当资源已经预留给 Pod 时，会通知插件。 这些插件还实现了 Unreserve 接口，在 Reserve 期间或之后出现故障时调用。 permit：这些插件可以阻止或延迟 Pod 绑定。 preBind：这些插件在 Pod 绑定节点之前执行。 bind：这个插件将 Pod 与节点绑定。bind 插件是按顺序调用的，只要有一个插件完成了绑定，其余插件都会跳过。bind 插件至少需要一个。 postBind：这是一个信息扩展点，在 Pod 绑定了节点之后调用。 multiPoint：这是一个仅配置字段，允许同时为所有适用的扩展点启用或禁用插件 调度策略 #调度器通过 Kubernetes 的监测（Watch）机制来发现集群中新创建且尚未被调度到节点上的 Pod。 调度器会将所发现的每一个未调度的 Pod 调度到一个合适的节点上来运行。 调度器会依据下文的调度原则来做出调度选择。\n调度流程 # 过滤 打分 ","date":"24.02.2023","permalink":"/posts/kubernetes/kubernetes/scheduler/","section":"Posts","summary":"kubernetes scheduler","title":"kubernetes scheduler"},{"content":"","date":null,"permalink":"/tags/scheduler/","section":"Tags","summary":"","title":"scheduler"},{"content":"","date":null,"permalink":"/tags/go/","section":"Tags","summary":"","title":"go"},{"content":"basic # 初始化 创建容器 id 下载 image 创建容器工作目录 挂载文件 overlay 方式 创建 veth pair 创建 netns 挂载 veth 支持的命令 # run child-mode setup-netns setup-veth ps exec images rmi container (overlay fs) #容器的工作目录\n/var/run/container/containers/containerId/fs /var/run/container/containers/containerId/fs/mnt /var/run/container/containers/containerId/fs/upperdir /var/run/container/containers/containerId/fs/workdir mount overlay file system #unix.mount() veth-pair #虚拟网络设备对,用于解决不同网络命名空间之间的通信\nfunc setupVirtualEthOnHost(containerID string) error { veth0 := \u0026#34;veth0_\u0026#34; + containerID[:6] veth1 := \u0026#34;veth1_\u0026#34; + containerID[:6] linkAttrs := netlink.NewLinkAttrs() linkAttrs.Name = veth0 veth0Struct := \u0026amp;netlink.Veth{ LinkAttrs: linkAttrs, PeerName: veth1, PeerHardwareAddr: createMACAddress(), } if err := netlink.LinkAdd(veth0Struct); err != nil { return err } netlink.LinkSetUp(veth0Struct) containerBridge, _ := netlink.LinkByName(\u0026#34;container0\u0026#34;) netlink.LinkSetMaster(veth0Struct, containerBridge) return nil } ","date":"29.10.2022","permalink":"/posts/docker/docker/create/","section":"Posts","summary":"通过使用 go 实现一个可用的 docker 来了解 docker 的工作原理。","title":"从零开始实现一个可用的 docker"},{"content":"关闭防火墙 #systemctl disable firewalld systemctl stop firewalld 关闭 selinux #setenforce 0 sed -i \u0026#39;s/SELINUX=permissive/SELINUX=disabled/\u0026#39; /etc/sysconfig/selinux sed -i \u0026#34;s/SELINUX=enforcing/SELINUX=disabled/g\u0026#34; /etc/selinux/config 关闭 swap #swapoff -a sed -i \u0026#39;s/.*swap.*/#\u0026amp;/\u0026#39; /etc/fstab 添加主机名与 IP 对应的关系 #hostnamectl set-hostname k8s-master vim /etc/hosts #添加如下内容： 10.0.24.13 k8s-master 将桥接的 IPV4 流量传递到 iptables 的链 #cat \u0026gt; /etc/sysctl.d/k8s.conf \u0026lt;\u0026lt; EOF net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sysctl --system yum #**rm -rfv /etc/yum.repos.d/* curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-8.repo yum install -y yum-utils yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo # 配置k8s阿里云源 cat \u0026lt;\u0026lt;EOF \u0026gt; /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/ enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF** 基础包 #yum install vim bash-completion net-tools gcc -y docker #yum install docker-ce systemctl start docker # 启动Docker systemctl enable docker # 设置自动启动 docker config #/etc/docker/daemon.json { \u0026#34;registry-mirrors\u0026#34;: [ \u0026#34;https://56tyyl4k.mirror.aliyuncs.com\u0026#34; ], \u0026#34;exec-opts\u0026#34;: [\u0026#34;native.cgroupdriver=systemd\u0026#34;] } systemctl daemon-reload systemctl restart docker kubernetes 组件 #yum install -y kubectl kubeadm kubelet systemctl enable kubelet \u0026amp;\u0026amp; systemctl start kubelet 初始化 #kubeadm init --image-repository registry.aliyuncs.com/google_containers --kubernetes-version v1.23.1 --pod-network-cidr=10.0.24.13/16 kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml kubectl config #mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config source \u0026lt;(kubectl completion bash) 污点 #kubectl taint nodes k8s-master node-role.kubernetes.io/master:NoSchedule- ","date":"26.10.2022","permalink":"/posts/kubernetes/kubernetes/mount/","section":"Posts","summary":"使用 kubeadm 在 liunx 上安装 kubernetes","title":"kubernetes 部署"},{"content":"部署 nfs server # 安装软件包 yum install -y rpcbind nfs-utils 修改 /etc/exports /hone/nfs/ \\*(insecure,rw,sync,no_root_squash) 启动 nfs 服务 mkdir /home/nfs systemctl enable rpcbind systemctl enable nfs-server systemctl start rpcbind systemctl start nfs-server exportfs -r exportfs 创建 RABC #用户创建 nfs client #apiVersion: v1 kind: ServiceAccount metadata: name: nfs-client-provisioner namespace: default --- kind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1 metadata: name: nfs-client-provisioner-runner rules: - apiGroups: [\u0026#39;\u0026#39;] resources: [\u0026#39;persistentvolumes\u0026#39;] verbs: [\u0026#39;get\u0026#39;, \u0026#39;list\u0026#39;, \u0026#39;watch\u0026#39;, \u0026#39;create\u0026#39;, \u0026#39;delete\u0026#39;] - apiGroups: [\u0026#39;\u0026#39;] resources: [\u0026#39;persistentvolumeclaims\u0026#39;] verbs: [\u0026#39;get\u0026#39;, \u0026#39;list\u0026#39;, \u0026#39;watch\u0026#39;, \u0026#39;update\u0026#39;] - apiGroups: [\u0026#39;storage.k8s.io\u0026#39;] resources: [\u0026#39;storageclasses\u0026#39;] verbs: [\u0026#39;get\u0026#39;, \u0026#39;list\u0026#39;, \u0026#39;watch\u0026#39;] - apiGroups: [\u0026#39;\u0026#39;] resources: [\u0026#39;events\u0026#39;] verbs: [\u0026#39;create\u0026#39;, \u0026#39;update\u0026#39;, \u0026#39;patch\u0026#39;] --- kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: run-nfs-client-provisioner subjects: - kind: ServiceAccount name: nfs-client-provisioner namespace: default roleRef: kind: ClusterRole name: nfs-client-provisioner-runner apiGroup: rbac.authorization.k8s.io --- kind: Role apiVersion: rbac.authorization.k8s.io/v1 metadata: name: leader-locking-nfs-client-provisioner namespace: default rules: - apiGroups: [\u0026#39;\u0026#39;] resources: [\u0026#39;endpoints\u0026#39;] verbs: [\u0026#39;get\u0026#39;, \u0026#39;list\u0026#39;, \u0026#39;watch\u0026#39;, \u0026#39;create\u0026#39;, \u0026#39;update\u0026#39;, \u0026#39;patch\u0026#39;] --- kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: leader-locking-nfs-client-provisioner namespace: default subjects: - kind: ServiceAccount name: nfs-client-provisioner namespace: default roleRef: kind: Role name: leader-locking-nfs-client-provisioner apiGroup: rbac.authorization.k8s.io 部署 nfs client #用于自动创建 pvc #apiVersion: apps/v1 kind: Deployment metadata: name: nfs-client-provisioner labels: app: nfs-client-provisioner namespace: default spec: replicas: 1 strategy: type: Recreate selector: matchLabels: app: nfs-client-provisioner template: metadata: labels: app: nfs-client-provisioner spec: serviceAccountName: nfs-client-provisioner containers: - name: nfs-client-provisioner image: registry.cn-hangzhou.aliyuncs.com/jimywu/nfs-subdir-external-provisioner:v4.0.0 volumeMounts: - name: nfs-client-root mountPath: /persistentvolumes env: - name: PROVISIONER_NAME value: k8s-sigs.io/nfs-subdir-external-provisioner - name: NFS_SERVER value: 10.0.24.13 - name: NFS_PATH value: /home/nfs volumes: - name: nfs-client-root nfs: server: 10.0.24.13 path: /home/nfs 创建 StorageClass #用于 mysql 自动扩容或者所容绑定 pvc #apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: mysql-storage provisioner: k8s-sigs.io/nfs-subdir-external-provisioner reclaimPolicy: Retain volumeBindingMode: Immediate 创建 StatefulSet #apiVersion: apps/v1 kind: StatefulSet metadata: name: mysql-backend spec: selector: matchLabels: app: mysql # 匹配 .spec.template.metadata.labels serviceName: mysql-svc-master replicas: 1 template: metadata: labels: app: mysql # 匹配 .spec.selector.matchLabels spec: initContainers: - name: init-mysql image: mysql:8.0 command: - bash - \u0026#39;-c\u0026#39; - | set ex # Generate mysql server-id from pod ordinal index. [[ `hostname` =~ -([0-9]+)$ ]] || exit 1 ordinal=${BASH_REMATCH[1]} echo [mysqld] \u0026gt; /mnt/conf.d/server-id.cnf # Add an offset to avoid reserved server-id=0 value. echo server-id=$((100 + $ordinal)) \u0026gt;\u0026gt; /mnt/conf.d/server-id.cnf # Copy appropriate conf.d files from config-map to emptyDir. if [[ $ordinal -eq 0 ]]; then cp /mnt/config-map/master.cnf /mnt/conf.d/ else cp /mnt/config-map/slave.cnf /mnt/conf.d/ fi volumeMounts: - name: conf mountPath: /mnt/conf.d - name: config-map mountPath: /mnt/config-map - name: clone-mysql image: mzmuer/xtrabackup:1.0 command: - bash - \u0026#39;-c\u0026#39; - | set -ex # Skip the clone if data already exists. [[ -d /var/lib/mysql/mysql ]] \u0026amp;\u0026amp; exit 0 # Skip the clone on master (ordinal index 0). [[ `hostname` =~ -([0-9]+)$ ]] || exit 1 ordinal=${BASH_REMATCH[1]} [[ $ordinal -eq 0 ]] \u0026amp;\u0026amp; exit 0 # Clone data from previous peer. ncat --recv-only mysql-ss-$(($ordinal-1)).mysql-svc-master 13306 | xbstream -x -C /var/lib/mysql # Prepare the backup. xtrabackup --prepare --target-dir=/var/lib/mysql volumeMounts: - name: data mountPath: /var/lib/mysql subPath: mysql - name: conf mountPath: /etc/mysql/conf.d containers: - name: mysql image: mysql:8.0 args: [\u0026#39;--default-authentication-plugin=mysql_native_password\u0026#39;] env: - name: MYSQL_ROOT_PASSWORD value: \u0026#39;4rt5$RT%\u0026#39; ports: - name: mysql containerPort: 3306 volumeMounts: - name: data mountPath: /var/lib/mysql subPath: mysql - name: conf mountPath: /etc/mysql/conf.d resources: requests: cpu: 250m memory: 256Mi limits: cpu: 500m memory: 512Mi livenessProbe: exec: command: [\u0026#39;mysqladmin\u0026#39;, \u0026#39;-uroot\u0026#39;, \u0026#39;-p${MYSQL_ROOT_PASSWORD}\u0026#39;, \u0026#39;ping\u0026#39;] initialDelaySeconds: 30 periodSeconds: 10 timeoutSeconds: 5 readinessProbe: exec: # Check we can execute queries over TCP (skip-networking is off). command: [\u0026#39;mysqladmin\u0026#39;, \u0026#39;-uroot\u0026#39;, \u0026#39;-p${MYSQL_ROOT_PASSWORD}\u0026#39;, \u0026#39;ping\u0026#39;] initialDelaySeconds: 5 periodSeconds: 2 timeoutSeconds: 1 - name: xtrabackup image: mzmuer/xtrabackup:1.0 ports: - name: xtrabackup containerPort: 13306 command: - bash - \u0026#39;-c\u0026#39; - | set -ex cd /var/lib/mysql # Determine binlog position of cloned data, if any. if [[ -s xtrabackup_slave_info ]]; then # XtraBackup already generated a partial \u0026#34;CHANGE MASTER TO\u0026#34; query # because we\u0026#39;re cloning from an existing slave. mv xtrabackup_slave_info change_master_to.sql.in # Ignore xtrabackup_binlog_info in this case (it\u0026#39;s useless). rm -f xtrabackup_binlog_info elif [[ -f xtrabackup_binlog_info ]]; then # We\u0026#39;re cloning directly from master. Parse binlog position. [[ `cat xtrabackup_binlog_info` =~ ^(.*?)[[:space:]]+(.*?)$ ]] || exit 1 rm xtrabackup_binlog_info echo \u0026#34;CHANGE MASTER TO MASTER_LOG_FILE=\u0026#39;${BASH_REMATCH[1]}\u0026#39;,\\ MASTER_LOG_POS=${BASH_REMATCH[2]}\u0026#34; \u0026gt; change_master_to.sql.in fi # Check if we need to complete a clone by starting replication. if [[ -f change_master_to.sql.in ]]; then echo \u0026#34;Waiting for mysqld to be ready (accepting connections)\u0026#34; until mysql -h 127.0.0.1 -e \u0026#34;SELECT 1\u0026#34;; do sleep 1; done echo \u0026#34;Initializing replication from clone position\u0026#34; # In case of container restart, attempt this at-most-once. mv change_master_to.sql.in change_master_to.sql.orig mysql -h 127.0.0.1 \u0026lt;\u0026lt;EOF $(\u0026lt;change_master_to.sql.orig), MASTER_HOST=\u0026#39;mysql-ss-0.mysql-svc-master\u0026#39;, MASTER_USER=\u0026#39;root\u0026#39;, MASTER_PASSWORD=\u0026#39;\u0026#39;, MASTER_CONNECT_RETRY=10; START SLAVE; EOF fi # Start a server to send backups when requested by peers. exec ncat --listen --keep-open --send-only --max-conns=1 13306 -c \\ \u0026#34;xtrabackup --backup --slave-info --stream=xbstream --host=127.0.0.1 --user=root\u0026#34; volumeMounts: - name: data mountPath: /var/lib/mysql subPath: mysql - name: conf mountPath: /etc/mysql/conf.d resources: requests: cpu: 100m memory: 100Mi limits: cpu: 200m memory: 200Mi volumes: - name: conf emptyDir: {} - name: config-map configMap: name: mysql volumeClaimTemplates: - metadata: name: data spec: storageClassName: \u0026#39;mysql-storage\u0026#39; accessModes: [\u0026#39;ReadWriteOnce\u0026#39;] resources: requests: storage: 10Gi ","date":"24.10.2022","permalink":"/posts/kubernetes/kubernetes/mysql/","section":"Posts","summary":"kubernetes 使用 stateful 方式部署 mysql","title":"stateful 部署 mysql"},{"content":"构建镜像 #docker build -t mysql:v8.0 查看 pod 的日志 #kubectl describe pod podname 进入容器 #kubectl exec -it podname bash 启动容器 #docker run -dit --name emqx -p 18083:18083 -p 1883:1883 -p 8083:8083 -p 8084:8084 -v /etc/localtime:/etc/localtime --restart=always emqx/emqx:latest 查看 container ## 运行的容器 docker ps # 所有的容器 docker ps -a #format docker ps --format \u0026#34;table {{.ID}} {{.Image}} {{.Names}} {{.Ports}}\u0026#34; # 删除停止的容器 docker container prune ","date":"24.10.2022","permalink":"/posts/docker/docker/basic/","section":"Posts","summary":"docker 基本的知识","title":"docker basic"},{"content":"查看子进程 # pstree 第一个进程是 systemd 脚本文件可执行权限 #chmod +x name.sh 输出 # echo \\t \\b 查看登录过的用户 #who who | wc -l 写文件 ##覆盖式的 echo \u0026#34;content\u0026#34; \u0026gt; name.text cat name.text #追加式 echo \u0026#34;new content\u0026#34; \u0026gt;\u0026gt; name.text 创建文件 #touch a b c touch \u0026#34;a b c\u0026#34; rm -rf a b c 备份文件 #tar -czf /root/log-`date +%Y%m%d`.tar.gz /var/log/ 移动文件和修改文件名 #mv name mame mv name /name 文本操作 ## text 要搜索的文本 file 供搜索的文件 grep text file -r 递归查找 -i 忽略大小写 -v 只显示搜索文本不在的那些行 -n 显示行号 对文件的行进行排序 #sort name.text -o 排序后写入新文件 -r 倒序排序 -R 随机排序 -n 对数学排序 wc #wc name.text -l 只统计行 -w 只统计单词数 -c 只统计字节数 -m 只统计字符数 cut #cut -c 2-4 name.text 输出重定向 #cut -d, -f 1 note.csv \u0026gt; name.csv 查看进程 #w # 当前系统的进程，相当于执行时的快照 ps # ef 列出所有进程; efH 以乔木状列举出所有进程; u 列出此用户运行的进程; aux 通过 CPU 和内存使用来过滤进程 ps -aux | less ; aux --sort -pcpu 按 CPU 使用降序排列， aux --sort -pmem 表示按内存使用降序排列; axjf 以树形结构显示进程， ps -axjf 它和 pstree 效果类似。 top #获取进程的动态列表\ntar #tar -cvf sort.tar sort/ tar -zcvf archive.tar.gz archive/ cvf 表示 create（创建）+ verbose（细节）+ file（文件），创建归档文件并显示操作细节； tf 显示归档里的内容，并不解开归档； rvf 追加文件到归档， tar -rvf archive.tar file.txt ； xvf 解开归档， tar -xvf archive.tar 。 ","date":"23.10.2022","permalink":"/posts/linux/linux/command/","section":"Posts","summary":"for linux command","title":"command"},{"content":"Mutex #互斥锁\n互斥锁的实现 #互斥锁是控制并发的基础手段。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) func main() { var counter Counter var wg sync.WaitGroup wg.Add(10) for i := 0; i \u0026lt; 10; i++ { go func() { defer wg.Done() for j := 0; j \u0026lt; 10000; j++ { counter.Lock() counter.Count++ counter.Unlock() } }() } wg.Wait() fmt.Println(counter.Count) } type Counter struct { sync.Mutex Count uint64 } Pool #创建池化的对象\nsync.Pool #sync.Pool 数据类型用来保存一组可独立访问的临时对象。\nsync.Pool 本身线程安全，多个 goroutine 可以并发地调用它的方法存取对象。 sync.Pool 不可在使用之后在复制使用。 sync.Pool 的使用方法 #new #pool struct 包含一个 new 字段，这个字段的类型是函数 func() interface{}。当调用 get 方法从池中获取元素的时候，没有空闲的元素可返回时，便会调用 new 新建一个元素返回。\nget #调用此方法从池中取走一个元素。\nput #此方法将一个元素返还给 pool，pool 将这个元素保存到池中并且可以复用。\nbuffer 缓冲池 #var buffers ={ New: func() interface{}{ return new(bytes.Buffer) }, } func GetBuffer() *bytes.Buffer{ return buffers.Get().(*bytes.Buffer) } func PutBuffer(buf *bytes.Buffer){ buf.Reset() buffers.Put(buf) } 实现原理 #Get 方法 #func (p *Pool) Get() interface{} { // 把当前 goroutine 固定在当前的p上 l, pid := p.pin() x :=l.private //优先从local 的 private字段取，快速 l.private = nil if x == nil { x,_ := l.shared.popHead() if x == nil{ x = p.getSlow(pid) } } runtime_procUnpin() // 如果没有获取到，尝试使用new函数生成一个新的 if x = nil \u0026amp;\u0026amp; p.New != nil { x = p.New() } return x } 内存泄露 #使用 sync.Pool 回收 buffer 的时候，一定要检查回收的对象的大小。\n","date":"23.10.2022","permalink":"/posts/go/go/sync/","section":"Posts","summary":"go stand library 基本的知识","title":"sync"},{"content":"","date":null,"permalink":"/tags/mysql/","section":"Tags","summary":"","title":"mysql"},{"content":"覆盖索引 # 就是 select 的数据列只用从索引中就能够取得，不必读取数据行，MySQL 可以利用索引返回 select 列表中的字段，而不必根据索引再次读取数据文件，换句话说查询列要被所建的索引覆盖。 索引是高效找到行的一个方法，但是一般数据库也能使用索引找到一个列的数据，因此它不必读取整个行。毕竟索引叶子节点存储了它们索引的数据，当能通过读取索引就可以得到想要的数据，那就不需要读取行了。一个索引包含（覆盖）满足查询结果的数据就叫做覆盖索引。 使用 explain，可以通过输出的 extra 列来判断，对于一个索引覆盖查询，显示为using index，MySQL 查询优化器在执行查询前会决定是否有索引覆盖查询 性能优化 # 慢查询日志，EXPLAIN 分析查询，profiling 分析以及show 命令查询系统状态及系统变量 explain # 表的读取顺序 数据读取操作的操作类型 哪些索引可以使用 哪些索引被实际使用 表之间的引用 每张表有多少行被优化器查询 ","date":"23.10.2022","permalink":"/posts/mysql/mysql/basic/","section":"Posts","summary":"mysql basic concept","title":"mysql basic"},{"content":" kubernetes 基本的知识\nPod #指定终止宽限期 #kubectl delete po podname --grace-period=5- token # kubectl -n kubernetes-dashboard get secret $(kubectl -n kubernetes-dashboard get sa/admin-user -o jsonpath=\u0026#34;{.secrets[0].name}\u0026#34;) -o go-template=\u0026#34;{{.data.token | base64decode}}\u0026#34; docker sercrets #kubectl create secret generic docker \\ --from-file=.dockerconfigjson=/root/.docker/config.json \\ --type=kubernetes.io/dockerconfigjson kubectl #多集群使用 kubectl #apiVersion: vl clusters: - cluster: certificate-authority: /home/sunweiwe/.minikube/ca.crt server: https://192.168.99.100:8443 name: minikube contexts: - context: cluster: minikube user: minikube namespace: default name: minikube current-context: minikube kind: Config preferences: {} users: - name: minikube user: client-certificate: /home/sunweiwe/ .minikube/apiserver.crt client-key: /home/sunweiwe/ .minikube/apiserver.key kubernetes 源码调试 #","date":"23.10.2022","permalink":"/posts/kubernetes/kubernetes/basic/","section":"Posts","summary":"\u003c!--abstract--\u003e\n\u003cp\u003ekubernetes 基本的知识\u003c/p\u003e","title":"kubernetes"},{"content":"","date":null,"permalink":"/tags/pprof/","section":"Tags","summary":"","title":"pprof"},{"content":"pprof 是什么？ #pprof 工具可以用来监测进程的运行数据，用于监控程序的性能，对内存使用和 CPU 使用的情况统信息进行分析。\n采样方式 # runtime/pprof：采集程序（非 Server）的指定区块的运行数据进行分析。 net/http/pprof：基于 HTTP Server 运行，并且可以采集运行时数据进行分析。 go test：通过运行测试用例，并指定所需标识来进行采集。 使用模式 # Report generation：报告生成。 Interactive terminal use：交互式终端使用。 (go tool pprof http://localhost:6060/debug/pprof/profile/(allocs|blocks|goroutine|etc..)) top list web Web interface：Web 界面。 使用方式 #package main import ( // 略 _ \u0026#34;net/http/pprof\u0026#34; // 会自动注册 handler 到 http server，方便通过 http 接口获取程序运行采样报告 // 略 ) func main() { // 略 runtime.GOMAXPROCS(1) // 限制 CPU 使用数，避免过载 runtime.SetMutexProfileFraction(1) // 开启对锁调用的跟踪 runtime.SetBlockProfileRate(1) // 开启对阻塞操作的跟踪 go func() { // 启动一个 http server，注意 pprof 相关的 handler 已经自动注册过了 if err := http.ListenAndServe(\u0026#34;:6060\u0026#34;, nil); err != nil { log.Fatal(err) } os.Exit(0) }() } 采集数据类型 # allocs 内存分配情况的采样信息 blocks 阻塞操作情况的采样信息 cmdline 显示程序启动命令及参数 goroutine 当前所有协程的堆栈信息 heap 堆上内存使用情况的采样信息 mutex 锁争用情况的采样信息 profile CPU 占用情况的采样信息 threadcreate 系统线程创建情况的采样信息 trace 程序运行跟踪信 ","date":"22.05.2022","permalink":"/posts/pprof/pprof/basic/","section":"Posts","summary":"pprof 工具可以用来监测进程的运行数据，用于监控程序的性能，对内存使用和 CPU 使用的情况统信息进行分析。","title":"pprof"},{"content":"","date":"01.01.0001","permalink":"/-about/","section":"","summary":"","title":""},{"content":"","date":null,"permalink":"/topics/","section":"Topics","summary":"","title":"Topics"}]